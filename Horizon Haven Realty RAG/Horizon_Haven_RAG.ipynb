{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "052ad7fc-90a3-42c0-a1f4-31ea23acbfa9",
   "metadata": {},
   "source": [
    "# RAG Powered Knowledge Base System\n",
    "The goal here is to build a robust question-and-answer agent using Retrieval-Augmented Generation (RAG). For this project, a knowledge base was created for a dummy real estate company, Horizon Haven Realty, using ChatGPT. By leveraging Chroma for the vector store and LangChain for seamless integration, the system efficiently retrieves relevant information to answer any queries. The Qwen3:4B model is used to generate accurate and contextually aware responses, creating a reliable Q&A system that can assist with real estate-related inquiries based on the companyâ€™s knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ee9b1-ea87-4ca7-8597-b55cfc150567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e228a40-d08d-45de-899c-a175cf117d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports for langchain, plotly and Chroma\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d421645-b024-424e-9b47-319e378f7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore harmless warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e5afc4-d7b7-4c40-b2d7-d185e6f65c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I will be using qwen3:4b model with langchain openai library\n",
    "\n",
    "MODEL = \"qwen3:4b\"\n",
    "db_name = \"hh_vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9315f27-f68b-4459-9ed4-626604b34860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take everything from all the sub-folders of our knowledgebase\n",
    "\n",
    "folders = glob.glob(\"Horizon_Haven_Realty_KnowledgeBase/*\")\n",
    "\n",
    "def add_metadata(doc, doc_type):\n",
    "    doc.metadata[\"doc_type\"] = doc_type\n",
    "    return doc\n",
    "\n",
    "text_loader_kwargs = {'encoding': 'utf-8'}\n",
    "\n",
    "# Read in documents using LangChain's loaders\n",
    "documents = []\n",
    "for folder in folders:\n",
    "    doc_type = os.path.basename(folder)\n",
    "    loader = DirectoryLoader(folder, glob=\"**/*.md\", loader_cls=TextLoader, loader_kwargs=text_loader_kwargs)\n",
    "    folder_docs = loader.load()\n",
    "    documents.extend([add_metadata(doc, doc_type) for doc in folder_docs])\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Total number of chunks: {len(chunks)}\")\n",
    "print(f\"Document types found: {set(doc.metadata['doc_type'] for doc in documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8be44c-1dd2-4fcf-b986-7fe445ebf412",
   "metadata": {},
   "source": [
    "We will be creating vector embeddings for each chunk of text. To do this, we'll use the __sentence-transformers/all-MiniLM-L6-v2__ model from Hugging Face to generate these embeddings. This model is efficient and well-suited for transforming text into vector representations, which will help us retrieve the most relevant information when queries are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bda071-f4d2-4594-9323-ae7783632fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the chunks of data into a Vector Store that associates a Vector Embedding with each chunk\n",
    "\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Delete if already exists\n",
    "\n",
    "if os.path.exists(db_name):\n",
    "    Chroma(persist_directory=db_name, embedding_function=embeddings).delete_collection()\n",
    "\n",
    "# Create vectorstore\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "print(f\"Vectorstore created with {vectorstore._collection.count()} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b09791d-34e4-468f-8f78-b1e320fa7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = vectorstore._collection\n",
    "count = collection.count()\n",
    "\n",
    "sample_embedding = collection.get(limit=1, include=[\"embeddings\"])[\"embeddings\"][0]\n",
    "dimensions = len(sample_embedding)\n",
    "print(f\"There are {count:,} vectors with {dimensions:,} dimensions in the vector store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561e8cd-5a15-4268-a7a1-38bf3ff6b06f",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "We will visualize the documents and their embedding vectors to better understand what's happening behind the scenes. To make it easier to interpret, we'll reduce the dimensionality to both 2D and 3D. This will give us a clearer view of how the vectors are distributed and how similar or different the documents are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d13d51-bd62-461a-a9d4-7e209a824d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collection.get(include=['embeddings', 'documents', 'metadatas'])\n",
    "vectors = np.array(result['embeddings'])\n",
    "documents = result['documents']\n",
    "metadatas = result['metadatas']\n",
    "doc_types = [metadata['doc_type'] for metadata in metadatas]\n",
    "colors = [['blue', 'green', 'red'][['Company', 'Contracts', 'Employees'].index(t)] for t in doc_types]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15a8dea-02b8-451d-bc31-49cd1495f93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the dimensionality of the vectors to 2D using t-SNE\n",
    "# (t-distributed stochastic neighbor embedding)\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 2D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='2D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x',yaxis_title='y'),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b40ef-bb06-404c-87d6-4a11b6bfc6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing in 3D\n",
    "\n",
    "tsne = TSNE(n_components=3, random_state=42)\n",
    "reduced_vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "# Create the 3D scatter plot\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=reduced_vectors[:, 0],\n",
    "    y=reduced_vectors[:, 1],\n",
    "    z=reduced_vectors[:, 2],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color=colors, opacity=0.8),\n",
    "    text=[f\"Type: {t}<br>Text: {d[:100]}...\" for t, d in zip(doc_types, documents)],\n",
    "    hoverinfo='text'\n",
    ")])\n",
    "\n",
    "fig.update_layout(\n",
    "    title='3D Chroma Vector Store Visualization',\n",
    "    scene=dict(xaxis_title='x', yaxis_title='y', zaxis_title='z'),\n",
    "    width=900,\n",
    "    height=700,\n",
    "    margin=dict(r=20, b=10, l=10, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a61dfb4-a482-4bfa-a07a-a3a7b0a8d2a7",
   "metadata": {},
   "source": [
    "## Let's use langchain to bring it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36d4a80-796e-4d95-9f47-3a9abe69b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Chat with OpenAI\n",
    "llm = ChatOpenAI(temperature=0.5, model_name=MODEL, base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# Set up the conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# The retriever is an abstraction over the VectorStore that will be used during RAG\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
    "\n",
    "# Putting it together\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093658ff-d9ce-4e5e-95b1-e970fda6fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample question\n",
    "query = \"What is Horizon Haven?\"\n",
    "result = conversation_chain.invoke({\"question\": query})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be67a4d-0bb9-49bd-b6ef-1f45d0926c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a new conversation memory for the chat\n",
    "memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "\n",
    "# Putting it together\n",
    "conversation_chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57930c5a-a8f8-46f5-be50-6f1529496e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question, history):\n",
    "    result = conversation_chain.invoke({\"question\": question})\n",
    "    return result[\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a5a03b-834a-4d9f-af3e-e46ae282c4be",
   "metadata": {},
   "source": [
    "## Finally\n",
    "We will create a function that allows us to chat with our model. The conversation will keep going until the user types \"exit,\" giving a seamless and interactive experience for querying the knowledge base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e55fe0-34e8-4842-bf8c-cfdbfaeaedc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "def ask_bot():\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() in ['exit', 'quit']:\n",
    "            print(\"Exiting chat.\")\n",
    "            break\n",
    "        answer = chat(user_input, chat_history)\n",
    "        chat_history.append((\"user\", user_input))\n",
    "        chat_history.append((\"bot\", answer))\n",
    "        display(Markdown(f\"**Bot:** {answer}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ccd44f-c5c3-4ef0-961d-d85e1cb1b79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_bot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68357696-2d44-4342-bd5c-1a47b4d0e4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
