{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc1099b-5c37-4749-b30c-926f28f70bc7",
   "metadata": {},
   "source": [
    "# Company Brochure Generator\n",
    "The idea is to create a brochure generator for companies. Once the company name and main website are provided, the tool will scan the site and filter out the most relevant links and content that would work well in a brochure. With the help of prompt engineering and a simple Gradio interface, the goal is to build an easy-to-use tool that can generate polished, professional brochures directly from the company’s existing web content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0c634-0c87-4813-8ab5-11cb464a2623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fcc171-ad2f-41fc-aa78-bfed673538ce",
   "metadata": {},
   "source": [
    "For this brochure generator, we will use the Qwen3:4B model. \n",
    "\n",
    "To demonstrate the process, we will use Enroot Earth as a sample website. \n",
    "\n",
    "You can check out the website at https://www.enroot.earth/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470de54-89dc-45eb-bbe1-3e02272b85f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "MODEL = 'qwen3:4b'\n",
    "WEBSITE_URL = 'https://www.enroot.earth/'\n",
    "COMPANY_NAME = 'Enroot Earth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58731bc2-dabd-4c69-9f48-1733cf41800c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to scrape a webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to scrape a website, with filtered links\n",
    "    \"\"\"\n",
    "\n",
    "    # List of file extensions to exclude (common downloadable file types)\n",
    "    EXCLUDED_EXTENSIONS = {\".pdf\", \".doc\", \".docx\", \".xls\", \".xlsx\", \".ppt\", \".pptx\", \".zip\", \".rar\", \".exe\", \".dmg\", \".tar\", \".gz\", \".7z\", \".mp3\", \".mp4\", \".avi\", \".mkv\", \".iso\"}\n",
    "\n",
    "    def __init__(self, url, headers=None):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        \n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        \n",
    "        # Extract and filter links\n",
    "        self.links = self.filter_links([link.get('href') for link in soup.find_all('a') if link.get('href')])\n",
    "\n",
    "    def filter_links(self, links):\n",
    "        \"\"\"Filters out links pointing to downloadable files and keeps only web pages, emails, \n",
    "        and social media links.\"\"\"\n",
    "        filtered_links = []\n",
    "        for link in links:\n",
    "            parsed_link = urlparse(link)\n",
    "            \n",
    "            # Keep email links\n",
    "            if parsed_link.scheme == \"mailto\":\n",
    "                filtered_links.append(link)\n",
    "                continue\n",
    "            \n",
    "            # Keep social media links\n",
    "            if any(domain in parsed_link.netloc for domain in [\"facebook.com\", \"twitter.com\", \"linkedin.com\", \"instagram.com\", \"t.me\", \"youtube.com\"]):\n",
    "                filtered_links.append(link)\n",
    "                continue\n",
    "            \n",
    "            # Ignore links with excluded extensions\n",
    "            if any(parsed_link.path.lower().endswith(ext) for ext in self.EXCLUDED_EXTENSIONS):\n",
    "                continue\n",
    "            \n",
    "            # Convert relative URLs to absolute URLs\n",
    "            absolute_link = urljoin(self.url, link)\n",
    "            filtered_links.append(absolute_link)\n",
    "        \n",
    "        return filtered_links\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeed73d-56a2-4e75-b933-bb902931eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "web = Website(WEBSITE_URL)\n",
    "web_links = web.links\n",
    "print(web_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21a5e4-b211-45f2-a694-0154f127df4c",
   "metadata": {},
   "source": [
    "First, we'll use the Qwen3:4B model via Ollama to figure out which links on the website are relevant. By making a call to the model, it will read the available links and return the results in a structured JSON format. The model will decide which links are most suitable for the brochure. \n",
    "\n",
    "To help it respond accurately, we'll use a __\"one-shot prompting\"__ approach, where an example of the expected response is included directly in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97bc591-447e-4898-ae66-dff261ede0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee5add5-219a-4449-a0bf-e39b7528bf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"Please decide which of these are relevant web links for a brochure about the company, \\\n",
    "    respond with the full https URL in JSON format. \\\n",
    "    Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bb3775-13ef-4c65-b09e-88c3bd4bfd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    result = response['message']['content'].strip()\n",
    "\n",
    "    # Remove <think>...</think> blocks\n",
    "    result = re.sub(r\"<think>.*?</think>\", \"\", result, flags=re.DOTALL).strip()\n",
    "\n",
    "    # Remove ```json and ``` if present\n",
    "    result = re.sub(r\"^```json|```$\", \"\", result.strip(), flags=re.MULTILINE).strip()\n",
    "\n",
    "    try:\n",
    "        return json.loads(result)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"⚠️ Failed to parse JSON. Raw model output:\\n\", result)\n",
    "        return {\"links\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd24aff-3cd4-4d89-953a-d4cfbe88a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_links = get_links(WEBSITE_URL)\n",
    "print(web_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1510634f-3f31-46d9-9147-1ad124ad5f1f",
   "metadata": {},
   "source": [
    "Now that we have the relevant links, we'll move on to generating the brochure. We'll start by extracting the content from each of the selected web pages. Once the content is ready, we'll ask the Qwen3:4B model to create a brochure using the gathered information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873941c6-efb1-465f-8b77-d3b0d03656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url, links_dict):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    \n",
    "    print(\"Found links:\", links_dict)\n",
    "\n",
    "    # Get the actual list of links from the dictionary\n",
    "    links = links_dict.get(\"links\", [])\n",
    "\n",
    "    for link_info in links:\n",
    "        link_url = link_info.get(\"url\")\n",
    "        if link_url:\n",
    "            result += Website(link_url).get_contents()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261483de-145a-4cbb-b0ed-7721b32b7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_all_details(WEBSITE_URL, web_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2bf74-f4cd-4754-ae44-eeb4643e4256",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. \\\n",
    "Respond in markdown.Include details of company culture, customers and careers/jobs if you have the information.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca858354-69c1-446e-961a-743d0701cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url, links):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; \\\n",
    "    Use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url, links)\n",
    "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501a0323-999d-4acb-9772-bacaab18f515",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_brochure_user_prompt(COMPANY_NAME, WEBSITE_URL, web_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6b83a9-7f90-4003-9e36-0e492918540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url, links):\n",
    "    response = ollama.chat(\n",
    "        model=MODEL, \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url, links)}\n",
    "        ]\n",
    "    )\n",
    "    result = response['message']['content'].strip()\n",
    "    \n",
    "    # Remove <think>...</think> blocks\n",
    "    result = re.sub(r\"<think>.*?</think>\", \"\", result, flags=re.DOTALL).strip()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70d1859-b695-40b5-b4ee-59b27eabadca",
   "metadata": {},
   "outputs": [],
   "source": [
    "brochure = create_brochure(COMPANY_NAME, WEBSITE_URL, web_links)\n",
    "display(Markdown(brochure))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592d1e0-e1eb-441d-a55d-f8cb7a8006b7",
   "metadata": {},
   "source": [
    "## A minor improvement\n",
    "With a small adjustment, we can change this so that the results are streamed back, with the familiar typewriter animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabac108-5ce2-4e42-bbad-4b36ceb9f984",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    links = get_links(url)\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url, links)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "\n",
    "    in_think_block = False\n",
    "    result_chunks = []\n",
    "    live_output = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        content = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "\n",
    "        # Skip <think> blocks\n",
    "        if \"<think>\" in content:\n",
    "            in_think_block = True\n",
    "            continue\n",
    "        elif \"</think>\" in content:\n",
    "            in_think_block = False\n",
    "            continue\n",
    "        elif in_think_block:\n",
    "            continue\n",
    "\n",
    "        result_chunks.append(content)\n",
    "        current_result = \"\".join(result_chunks).strip()\n",
    "        live_output.update(Markdown(current_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa065378-1ec8-4793-9062-d1c7a593e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_brochure(COMPANY_NAME, WEBSITE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21842b4f-c186-456e-b6ed-39de8580a86c",
   "metadata": {},
   "source": [
    "## Finally\n",
    "We'll build a simple and interactive user interface using Gradio. This will allow anyone to easily input a company name and website, and instantly generate a polished brochure. The goal is to make the entire process seamless and user-friendly, requiring no technical expertise from the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a63e4a-a6a4-4b7f-9415-fc0e5bf426cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882dfb35-cee2-4557-9659-5ed3e5565b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    links = get_links(url)\n",
    "    stream = ollama.chat(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url, links)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    in_think_block = False\n",
    "    result_so_far = \"\"\n",
    "    \n",
    "    for chunk in stream:\n",
    "        content = chunk.get(\"message\", {}).get(\"content\", \"\")\n",
    "        # Skip <think> blocks\n",
    "        if \"<think>\" in content:\n",
    "            in_think_block = True\n",
    "            continue\n",
    "        elif \"</think>\" in content:\n",
    "            in_think_block = False\n",
    "            continue\n",
    "        elif in_think_block:\n",
    "            continue\n",
    "            \n",
    "        result_so_far += content\n",
    "        yield result_so_far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf50197f-dfbb-4162-a9d3-f6b505bc2434",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks(title=\"Company Brochure Generator\") as demo:\n",
    "    gr.Markdown(\"# Company Brochure Generator\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            company_name = gr.Textbox(label=\"Company name:\")\n",
    "            url = gr.Textbox(label=\"Landing page URL (including http:// or https://)\")\n",
    "            generate_btn = gr.Button(\"Generate Brochure\")\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            output = gr.Markdown(label=\"Brochure:\")\n",
    "    \n",
    "    generate_btn.click(\n",
    "        fn=stream_brochure,\n",
    "        inputs=[company_name, url],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28929afb-57b8-406b-9b56-32f492dc04f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c2e8d-b2d1-415a-a1e7-c9dfc90796b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
