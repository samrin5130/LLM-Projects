{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b04c2741-4506-4b9f-b3b3-a366892a6d43",
   "metadata": {},
   "source": [
    "# Product Pricer: LLaMA 3.1 Fine-Tuned Price Prediction from Descriptions\n",
    "The goal of this project is to build a Product Pricer, an AI-powered tool that predicts the price of an item based solely on its description. To achieve this, a __LLaMA 3.1-8B__ model has been fine-tuned using __LoRA (Low-Rank Adaptation) with 4-bit quantization__, making the model both efficient and cost-effective to run. The training dataset is sourced from https://huggingface.co/datasets/McAuley-Lab/Amazon-Reviews-2023 on Hugging Face, which provides a rich collection of item descriptions and corresponding prices. The workflow involves carefully cleaning the dataset, setting up a dedicated __items.py__ class to handle preprocessing, data management, and utility functions, and finally fine-tuning the model to accurately predict prices. The project also includes evaluation steps to assess the model’s performance and ensure reliable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3654a3-3948-4923-a416-526528a86832",
   "metadata": {},
   "source": [
    "## Base Model Evaluation\n",
    "Before we fine-tune our model, we’ll first evaluate the performance using the base LLaMA 3.1-8B model. This will give us a useful baseline to compare how much improvement fine-tuning brings. You can check out the evaluation process in this notebook: **Pricer_Base_Eval.ipynb**. \n",
    "\n",
    "**Tip:** If your local machine doesn’t have enough computational power, consider running this notebook on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd6a5d0-8b38-46ff-b0f1-8f9ea6e4587b",
   "metadata": {},
   "source": [
    "## Fine Tuning\n",
    "Now we’ll move on to fine-tuning our LLaMA 3.1-8B model using LoRA and 4-bit quantization. This approach helps us make the fine-tuning process more efficient while keeping the model lightweight for deployment. You can follow the fine-tuning steps in this notebook: **Pricer_fine_tuned_1.ipynb**. \n",
    "\n",
    "**Tip:** If your local machine doesn’t have enough computational power, consider running this notebook on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e229de2-6b01-47d9-8376-b478a00c4046",
   "metadata": {},
   "source": [
    "## Fine Tuned Model Evaluation\n",
    "Finally, we’ll evaluate our fine-tuned model to see how well it performs on predicting item prices. This will help us compare the results against our baseline and understand the improvements gained from fine-tuning. You can check out the evaluation process in this notebook: **Pricer_Eval.ipynb**. \n",
    "\n",
    "**Tip:** If your local machine doesn’t have enough computational power, consider running this notebook on Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf201115-434e-4d5b-b88b-955336d62aba",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
